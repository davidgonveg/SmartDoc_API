# docker-compose.yml - CORREGIDO basado en estructura original

services:
  # Redis for caching and session storage - OPTIMIZADO
  redis:
    image: redis:7-alpine
    container_name: smartdoc-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  # ChromaDB for vector storage - OPTIMIZADO
  chromadb:
    image: chromadb/chroma:latest
    container_name: smartdoc-chromadb
    ports:
      - "8000:8000"
    volumes:
      - chromadb_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_GRPC_PORT=50051
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  # Ollama LLM Service - AGREGADO Y OPTIMIZADO
  ollama:
    image: ollama/ollama:latest
    container_name: smartdoc-ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_KEEP_ALIVE=5m
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          memory: 2G

  # Agent API (FastAPI + LangChain) - OPTIMIZADO
  agent-api:
    build: 
      context: ./agent-api
      dockerfile: Dockerfile
    container_name: smartdoc-agent-api
    ports:
      - "8002:8001"
    volumes:
      - ./data/uploads:/app/uploads
      - ./data/reports:/app/reports
      - ./logs/agent:/app/logs
    environment:
      # Configuraci√≥n original
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_HOST=ollama  # ‚Üê CAMBIADO: ahora usa el servicio ollama
      - OLLAMA_PORT=11434
      
      # üöÄ NUEVOS: Par√°metros LLM optimizados
      - LLM_TEMPERATURE=0.7
      - LLM_TOP_P=0.9
      - LLM_NUM_CTX=8192
      - LLM_NUM_PREDICT=1024
      - LLM_TIMEOUT=300
      
      # üöÄ NUEVOS: Configuraci√≥n del agente
      - AGENT_MAX_ITERATIONS=15
      - AGENT_OPTIMIZATION_LEVEL=balanced
      - AGENT_ENABLE_STREAMING=true
      - AGENT_MAX_EXECUTION_TIME=300
      
      # üöÄ NUEVOS: Configuraci√≥n de memoria
      - MEMORY_WINDOW_SIZE=10
      - MEMORY_MAX_STORED_STEPS=50
      
      # üöÄ NUEVOS: Configuraci√≥n de herramientas
      - WEB_SEARCH_TIMEOUT=30
      - WEB_SEARCH_MAX_RESULTS=10
      - WEB_SEARCH_RATE_LIMIT=5
      
      # üöÄ NUEVOS: Performance settings
      - ENABLE_GPU=true
      - MAX_CONCURRENT_SESSIONS=10
      - CACHE_TTL=3600
      - DEFAULT_MODEL=llama3.2:3b
    depends_on:
      - redis
      - chromadb
      - ollama  # ‚Üê AGREGADO: depende de ollama
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # Streamlit UI - MANTENIDO ORIGINAL
  streamlit-ui:
    build:
      context: ./streamlit-ui  # ‚Üê CORRECTO: tu directorio real
      dockerfile: Dockerfile
    container_name: smartdoc-streamlit-ui
    ports:
      - "8501:8501"
    volumes:
      - ./data/uploads:/app/uploads
      - ./data/reports:/app/reports
    environment:
      - AGENT_API_URL=http://agent-api:8001
      - STREAMLIT_THEME=dark
      - STREAMLIT_SERVER_MAX_UPLOAD_SIZE=200
      - STREAMLIT_SERVER_ENABLE_CORS=true
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
    depends_on:
      - agent-api
    restart: unless-stopped

volumes:
  redis_data:
    driver: local
  chromadb_data:
    driver: local
  ollama_data:    # ‚Üê AGREGADO: volumen para ollama
    driver: local

networks:
  default:
    name: smartdoc-network